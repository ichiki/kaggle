{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_train_data(path):\n",
    "    train = pd.read_csv(path)\n",
    "    \n",
    "    train['Sex'][train['Sex'] == 'male'] = 0\n",
    "    train['Sex'][train['Sex'] == 'female'] = 1\n",
    "    train['Sex'] = train['Sex'].astype(int)\n",
    "    \n",
    "    fill_train = train.iloc[:, [0,1,2,4,5,6,7,9]]\n",
    "    med = fill_train['Age'].median()\n",
    "    fill_train.loc[:, 'Age'] = fill_train['Age'].fillna(med)\n",
    "    \n",
    "    fill_train = fill_train.values\n",
    "    ids = fill_train[:, 0]\n",
    "    labels = fill_train[:, 1]\n",
    "    data = fill_train[:, 2:]\n",
    "    \n",
    "    return ids, data, labels, med"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(891, 6)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "train_ids, train_data, train_labels, med = load_train_data('data/train.csv')\n",
    "print(train_data.shape)\n",
    "\n",
    "# データを揃える\n",
    "## 平均取る\n",
    "train_mean = np.mean(train_data, axis=0)\n",
    "train_std = np.std(train_data, axis=0)\n",
    "\n",
    "## 正規化 (normlize / standard)\n",
    "## 分布を揃える\n",
    "## (trainデータ - 平均) / 分散\n",
    "train_data = (train_data - train_mean) / train_std\n",
    "\n",
    "# 学習データの準備\n",
    "## validation data\n",
    "val_data = train_data[-100:] # 後ろから100番目とる\n",
    "val_labels = train_labels[-100:]\n",
    "## train data\n",
    "train_data = train_data[:-100] # 後ろから数えて100個目まで取る\n",
    "train_labels = train_labels[:-100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 2.30864198,  0.35241302, 29.36158249,  0.52300786,  0.38159371,\n",
       "       32.20420797])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 0.83560193,  0.47772176, 13.01238827,  1.10212444,  0.80560476,\n",
       "       49.66553444])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/tensorboard/compat/tensorflow_stub/dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TitanicModel(tf.keras.Model):\n",
    "    def __init__(self, output_dim):\n",
    "        super(TitanicModel, self).__init__()\n",
    "        # activation : 関数\n",
    "        self.dense1 = layers.Dense(16, activation='relu') # 16次元に拡張\n",
    "        self.dense2 = layers.Dense(16, activation='relu') # 16次元の層\n",
    "        # 0~1で収める処理\n",
    "        self.out = layers.Dense(output_dim, activation='sigmoid') # 1次元で0,1判定するときにsigmoidを利用. softmax\n",
    "        \n",
    "    def call(self, inputs):\n",
    "        # 分岐判定を作るならここで\n",
    "        # inputの次元定義しなくても勝手に設定してくれる\n",
    "        # callしたら、一番最初の次元固定で処理する\n",
    "        ## keras : define and run (対義語 difine by run)\n",
    "        x = self.dense1(inputs)\n",
    "        x = self.dense2(x)\n",
    "        x = self.out(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def scheduler(epoch):\n",
    "  # epoch : データを\n",
    "  if epoch < 25:\n",
    "    return 0.001\n",
    "  else:\n",
    "    return 0.001 * 0.9 ** (epoch - 24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 791 samples, validate on 100 samples\n",
      "Epoch 1/50\n",
      "791/791 [==============================] - 1s 706us/sample - loss: 0.6374 - acc: 0.6498 - val_loss: 0.5622 - val_acc: 0.7900\n",
      "Epoch 2/50\n",
      "791/791 [==============================] - 0s 324us/sample - loss: 0.5336 - acc: 0.7813 - val_loss: 0.4591 - val_acc: 0.8000\n",
      "Epoch 3/50\n",
      "791/791 [==============================] - 0s 328us/sample - loss: 0.4642 - acc: 0.7965 - val_loss: 0.4140 - val_acc: 0.8100\n",
      "Epoch 4/50\n",
      "791/791 [==============================] - 0s 360us/sample - loss: 0.4468 - acc: 0.7990 - val_loss: 0.3966 - val_acc: 0.8200\n",
      "Epoch 5/50\n",
      "791/791 [==============================] - 0s 310us/sample - loss: 0.4381 - acc: 0.8053 - val_loss: 0.3864 - val_acc: 0.8400\n",
      "Epoch 6/50\n",
      "791/791 [==============================] - 0s 290us/sample - loss: 0.4336 - acc: 0.8028 - val_loss: 0.3754 - val_acc: 0.8400\n",
      "Epoch 7/50\n",
      "791/791 [==============================] - 0s 349us/sample - loss: 0.4291 - acc: 0.8078 - val_loss: 0.3701 - val_acc: 0.8400\n",
      "Epoch 8/50\n",
      "791/791 [==============================] - 0s 359us/sample - loss: 0.4248 - acc: 0.8091 - val_loss: 0.3621 - val_acc: 0.8300\n",
      "Epoch 9/50\n",
      "791/791 [==============================] - 0s 328us/sample - loss: 0.4239 - acc: 0.8116 - val_loss: 0.3607 - val_acc: 0.8600\n",
      "Epoch 10/50\n",
      "791/791 [==============================] - 0s 330us/sample - loss: 0.4207 - acc: 0.8192 - val_loss: 0.3667 - val_acc: 0.8500\n",
      "Epoch 11/50\n",
      "791/791 [==============================] - 0s 333us/sample - loss: 0.4193 - acc: 0.8281 - val_loss: 0.3583 - val_acc: 0.8800\n",
      "Epoch 12/50\n",
      "791/791 [==============================] - 0s 361us/sample - loss: 0.4176 - acc: 0.8192 - val_loss: 0.3535 - val_acc: 0.8700\n",
      "Epoch 13/50\n",
      "791/791 [==============================] - 0s 301us/sample - loss: 0.4153 - acc: 0.8243 - val_loss: 0.3507 - val_acc: 0.8800\n",
      "Epoch 14/50\n",
      "791/791 [==============================] - 0s 292us/sample - loss: 0.4151 - acc: 0.8281 - val_loss: 0.3479 - val_acc: 0.8700\n",
      "Epoch 15/50\n",
      "791/791 [==============================] - 0s 299us/sample - loss: 0.4131 - acc: 0.8255 - val_loss: 0.3444 - val_acc: 0.8700\n",
      "Epoch 16/50\n",
      "791/791 [==============================] - 0s 345us/sample - loss: 0.4119 - acc: 0.8230 - val_loss: 0.3457 - val_acc: 0.8700\n",
      "Epoch 17/50\n",
      "791/791 [==============================] - 0s 319us/sample - loss: 0.4102 - acc: 0.8293 - val_loss: 0.3456 - val_acc: 0.8700\n",
      "Epoch 18/50\n",
      "791/791 [==============================] - 0s 408us/sample - loss: 0.4090 - acc: 0.8281 - val_loss: 0.3468 - val_acc: 0.8800\n",
      "Epoch 19/50\n",
      "791/791 [==============================] - 0s 432us/sample - loss: 0.4065 - acc: 0.8344 - val_loss: 0.3467 - val_acc: 0.8800\n",
      "Epoch 20/50\n",
      "791/791 [==============================] - 0s 446us/sample - loss: 0.4073 - acc: 0.8243 - val_loss: 0.3377 - val_acc: 0.8700\n",
      "Epoch 21/50\n",
      "791/791 [==============================] - 0s 511us/sample - loss: 0.4066 - acc: 0.8306 - val_loss: 0.3364 - val_acc: 0.8700\n",
      "Epoch 22/50\n",
      "791/791 [==============================] - 0s 512us/sample - loss: 0.4064 - acc: 0.8268 - val_loss: 0.3385 - val_acc: 0.8700\n",
      "Epoch 23/50\n",
      "791/791 [==============================] - 0s 470us/sample - loss: 0.4042 - acc: 0.8281 - val_loss: 0.3401 - val_acc: 0.8700\n",
      "Epoch 24/50\n",
      "791/791 [==============================] - 1s 684us/sample - loss: 0.4040 - acc: 0.8243 - val_loss: 0.3393 - val_acc: 0.8700\n",
      "Epoch 25/50\n",
      "791/791 [==============================] - 0s 563us/sample - loss: 0.4031 - acc: 0.8306 - val_loss: 0.3366 - val_acc: 0.8700\n",
      "Epoch 26/50\n",
      "791/791 [==============================] - 1s 755us/sample - loss: 0.4003 - acc: 0.8319 - val_loss: 0.3456 - val_acc: 0.8700\n",
      "Epoch 27/50\n",
      "791/791 [==============================] - 0s 533us/sample - loss: 0.4008 - acc: 0.8281 - val_loss: 0.3350 - val_acc: 0.8700\n",
      "Epoch 28/50\n",
      "791/791 [==============================] - 0s 505us/sample - loss: 0.3987 - acc: 0.8319 - val_loss: 0.3329 - val_acc: 0.8600\n",
      "Epoch 29/50\n",
      "791/791 [==============================] - 0s 266us/sample - loss: 0.3990 - acc: 0.8255 - val_loss: 0.3383 - val_acc: 0.8700\n",
      "Epoch 30/50\n",
      "791/791 [==============================] - 0s 271us/sample - loss: 0.3974 - acc: 0.8306 - val_loss: 0.3394 - val_acc: 0.8700\n",
      "Epoch 31/50\n",
      "791/791 [==============================] - 0s 281us/sample - loss: 0.3975 - acc: 0.8281 - val_loss: 0.3376 - val_acc: 0.8700\n",
      "Epoch 32/50\n",
      "791/791 [==============================] - 0s 279us/sample - loss: 0.3952 - acc: 0.8344 - val_loss: 0.3350 - val_acc: 0.8700\n",
      "Epoch 33/50\n",
      "791/791 [==============================] - 0s 271us/sample - loss: 0.3944 - acc: 0.8331 - val_loss: 0.3389 - val_acc: 0.8700\n",
      "Epoch 34/50\n",
      "791/791 [==============================] - 0s 348us/sample - loss: 0.3952 - acc: 0.8306 - val_loss: 0.3369 - val_acc: 0.8700\n",
      "Epoch 35/50\n",
      "791/791 [==============================] - 0s 306us/sample - loss: 0.3940 - acc: 0.8331 - val_loss: 0.3376 - val_acc: 0.8700\n",
      "Epoch 36/50\n",
      "791/791 [==============================] - 0s 302us/sample - loss: 0.3930 - acc: 0.8357 - val_loss: 0.3340 - val_acc: 0.8600\n",
      "Epoch 37/50\n",
      "791/791 [==============================] - 0s 336us/sample - loss: 0.3935 - acc: 0.8331 - val_loss: 0.3357 - val_acc: 0.8700\n",
      "Epoch 38/50\n",
      "791/791 [==============================] - 0s 303us/sample - loss: 0.3930 - acc: 0.8306 - val_loss: 0.3368 - val_acc: 0.8700\n",
      "Epoch 39/50\n",
      "791/791 [==============================] - 0s 287us/sample - loss: 0.3924 - acc: 0.8344 - val_loss: 0.3367 - val_acc: 0.8700\n",
      "Epoch 40/50\n",
      "791/791 [==============================] - 0s 285us/sample - loss: 0.3919 - acc: 0.8331 - val_loss: 0.3353 - val_acc: 0.8700\n",
      "Epoch 41/50\n",
      "791/791 [==============================] - 0s 269us/sample - loss: 0.3918 - acc: 0.8319 - val_loss: 0.3355 - val_acc: 0.8700\n",
      "Epoch 42/50\n",
      "791/791 [==============================] - 0s 267us/sample - loss: 0.3914 - acc: 0.8331 - val_loss: 0.3355 - val_acc: 0.8700\n",
      "Epoch 43/50\n",
      "791/791 [==============================] - 0s 285us/sample - loss: 0.3911 - acc: 0.8319 - val_loss: 0.3358 - val_acc: 0.8700\n",
      "Epoch 44/50\n",
      "791/791 [==============================] - 0s 310us/sample - loss: 0.3910 - acc: 0.8331 - val_loss: 0.3363 - val_acc: 0.8700\n",
      "Epoch 45/50\n",
      "791/791 [==============================] - 0s 586us/sample - loss: 0.3908 - acc: 0.8344 - val_loss: 0.3356 - val_acc: 0.8700\n",
      "Epoch 46/50\n",
      "791/791 [==============================] - 0s 447us/sample - loss: 0.3907 - acc: 0.8331 - val_loss: 0.3355 - val_acc: 0.8700\n",
      "Epoch 47/50\n",
      "791/791 [==============================] - 0s 356us/sample - loss: 0.3906 - acc: 0.8331 - val_loss: 0.3360 - val_acc: 0.8700\n",
      "Epoch 48/50\n",
      "791/791 [==============================] - 0s 295us/sample - loss: 0.3903 - acc: 0.8331 - val_loss: 0.3358 - val_acc: 0.8700\n",
      "Epoch 49/50\n",
      "791/791 [==============================] - 0s 344us/sample - loss: 0.3902 - acc: 0.8344 - val_loss: 0.3360 - val_acc: 0.8700\n",
      "Epoch 50/50\n",
      "791/791 [==============================] - 0s 352us/sample - loss: 0.3901 - acc: 0.8344 - val_loss: 0.3363 - val_acc: 0.8700\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x129ee6e48>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "model = TitanicModel(output_dim=1)\n",
    "# optimizer : 基本何やっているか分からない\n",
    "# Adamが自動で調整してくれる. learning_rate : うまくいかないときに調整するparams\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "              # lossについて\n",
    "              # sigmoid : negative log_lossを利用\n",
    "              # softmax -> cross entropy\n",
    "              # 回帰 -> mean squared loss, L1\n",
    "\n",
    "              loss=tf.losses.log_loss,\n",
    "              # loss='binary_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "ckpt_path = './ckpt/titanic/titanic'\n",
    "logdir=\"./logs/titanic-\" + datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "# logdir = \"./logs\"\n",
    "# ModelCheckpoint : 重みを自動で付けてくれる\n",
    "# TensorBoard : どう学習が進んでいるのか見れるようにする\n",
    "## tensorboard --logdir=logs で実行.localhost:6006で閲覧\n",
    "# LearningRateScheduler : 重みの更新と学習が進むごとのlearning_rateのチューニング\n",
    "callbacks = [tf.keras.callbacks.ModelCheckpoint(ckpt_path, save_best_only=True, monitor='val_acc'),\n",
    "             tf.keras.callbacks.TensorBoard(log_dir=logdir, histogram_freq=1),\n",
    "             tf.keras.callbacks.LearningRateScheduler(scheduler),\n",
    "            ]\n",
    "# ⊿Wの計算\n",
    "# batch : 1回の重みの更新\n",
    "# batch_size=4 : 1 itelationで4サンプルの使用していることを意味\n",
    "# 1 ecpock = (781/4). epochs = 50で 1epocksを50回実施\n",
    "model.fit(train_data, train_labels, batch_size=4, epochs=50, callbacks=callbacks,\n",
    "          validation_data=(val_data, val_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "87\n"
     ]
    }
   ],
   "source": [
    "cnt = 0\n",
    "for IDX in range(100):\n",
    "    predict = model.predict(val_data[IDX:IDX + 1])[0][0]\n",
    "    if predict > 0.5:\n",
    "        pred_label = 1\n",
    "    else:\n",
    "        pred_label = 0\n",
    "    # print(pred_label, val_labels[IDX], pred_label == val_labels[IDX])\n",
    "    if pred_label == val_labels[IDX]:\n",
    "        cnt += 1\n",
    "print(cnt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.training.tracking.util.CheckpointLoadStatus at 0x12a963978>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.load_weights(ckpt_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_test_data(path, med):\n",
    "    test = pd.read_csv(path)\n",
    "    \n",
    "    test['Sex'][test['Sex'] == 'male'] = 0\n",
    "    test['Sex'][test['Sex'] == 'female'] = 1\n",
    "    test['Sex'] = test['Sex'].astype(int)\n",
    "    \n",
    "    fill = test.iloc[:, [0,1,3,4,5,6,8]]\n",
    "    fill.loc[:, 'Age'] = fill['Age'].fillna(med)\n",
    "    \n",
    "    fill = fill.values\n",
    "    ids = fill[:, 0]\n",
    "    data = fill[:, 1:]\n",
    "    \n",
    "    return ids, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  \"\"\"\n",
      "/Users/ichikiyamasato/.pyenv/versions/3.6.0/lib/python3.6/site-packages/pandas/core/indexing.py:494: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  self.obj[item] = s\n"
     ]
    }
   ],
   "source": [
    "test_ids, test_data = load_test_data('data/test.csv', med)\n",
    "test_data = (test_data - train_mean) / train_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test dataを導入\n",
    "predictions = model.predict(test_data)\n",
    "\n",
    "result = []\n",
    "for id, pred in zip (test_ids, predictions):\n",
    "    if pred[0] < 0.5:\n",
    "        label = 0\n",
    "    else:\n",
    "        label = 1\n",
    "    result.append('%d,%d' % (id, label))\n",
    "    \n",
    "with open('result.csv', 'w') as fout:\n",
    "    fout.write('PassengerId,Survived\\n')\n",
    "    fout.write('\\n'.join(result))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "418"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.11777797],\n",
       "       [0.3803744 ],\n",
       "       [0.09675562],\n",
       "       [0.12236565],\n",
       "       [0.5581681 ],\n",
       "       [0.19540974],\n",
       "       [0.6065711 ],\n",
       "       [0.25720906],\n",
       "       [0.6471713 ],\n",
       "       [0.09003505],\n",
       "       [0.12126753],\n",
       "       [0.31761548],\n",
       "       [0.9880656 ],\n",
       "       [0.08899257],\n",
       "       [0.98172957],\n",
       "       [0.92703974],\n",
       "       [0.15615001],\n",
       "       [0.14009541],\n",
       "       [0.5646351 ],\n",
       "       [0.5163789 ],\n",
       "       [0.29926986],\n",
       "       [0.48647267],\n",
       "       [0.97973514],\n",
       "       [0.6829626 ],\n",
       "       [0.82455117],\n",
       "       [0.07786891],\n",
       "       [0.98054814],\n",
       "       [0.13452405],\n",
       "       [0.34836778],\n",
       "       [0.07570651],\n",
       "       [0.11498386],\n",
       "       [0.1680682 ],\n",
       "       [0.39165708],\n",
       "       [0.45663774],\n",
       "       [0.46157908],\n",
       "       [0.15310279],\n",
       "       [0.61236715],\n",
       "       [0.6341326 ],\n",
       "       [0.12722161],\n",
       "       [0.16634741],\n",
       "       [0.1332728 ],\n",
       "       [0.40318978],\n",
       "       [0.11411482],\n",
       "       [0.92096376],\n",
       "       [0.9810474 ],\n",
       "       [0.12618506],\n",
       "       [0.32811046],\n",
       "       [0.12124199],\n",
       "       [0.97084105],\n",
       "       [0.41996098],\n",
       "       [0.5274064 ],\n",
       "       [0.18291664],\n",
       "       [0.87511027],\n",
       "       [0.9136387 ],\n",
       "       [0.18025357],\n",
       "       [0.14088392],\n",
       "       [0.11752543],\n",
       "       [0.12601966],\n",
       "       [0.0911119 ],\n",
       "       [0.9752264 ],\n",
       "       [0.16630414],\n",
       "       [0.165407  ],\n",
       "       [0.15762648],\n",
       "       [0.6280124 ],\n",
       "       [0.32972443],\n",
       "       [0.9259213 ],\n",
       "       [0.6479477 ],\n",
       "       [0.32950228],\n",
       "       [0.39307833],\n",
       "       [0.71659666],\n",
       "       [0.6214724 ],\n",
       "       [0.14059994],\n",
       "       [0.6096541 ],\n",
       "       [0.4024948 ],\n",
       "       [0.9787977 ],\n",
       "       [0.49678925],\n",
       "       [0.12129456],\n",
       "       [0.97439325],\n",
       "       [0.17086437],\n",
       "       [0.6214724 ],\n",
       "       [0.47321495],\n",
       "       [0.5447837 ],\n",
       "       [0.30105516],\n",
       "       [0.12126753],\n",
       "       [0.17428756],\n",
       "       [0.09093583],\n",
       "       [0.61444885],\n",
       "       [0.6481517 ],\n",
       "       [0.61173224],\n",
       "       [0.67448676],\n",
       "       [0.5930767 ],\n",
       "       [0.1212464 ],\n",
       "       [0.9688852 ],\n",
       "       [0.12129456],\n",
       "       [0.41872722],\n",
       "       [0.12610734],\n",
       "       [0.9599179 ],\n",
       "       [0.1207318 ],\n",
       "       [0.6381025 ],\n",
       "       [0.11861077],\n",
       "       [0.9817605 ],\n",
       "       [0.18336514],\n",
       "       [0.12124199],\n",
       "       [0.12291425],\n",
       "       [0.6273027 ],\n",
       "       [0.13152698],\n",
       "       [0.14054349],\n",
       "       [0.12124199],\n",
       "       [0.12141049],\n",
       "       [0.24028087],\n",
       "       [0.14808425],\n",
       "       [0.6117941 ],\n",
       "       [0.9762676 ],\n",
       "       [0.64479125],\n",
       "       [0.96954346],\n",
       "       [0.1280739 ],\n",
       "       [0.12101254],\n",
       "       [0.7814176 ],\n",
       "       [0.4217642 ],\n",
       "       [0.9230703 ],\n",
       "       [0.93549466],\n",
       "       [0.0903486 ],\n",
       "       [0.9840964 ],\n",
       "       [0.12115452],\n",
       "       [0.12124199],\n",
       "       [0.6839044 ],\n",
       "       [0.1367797 ],\n",
       "       [0.4690193 ],\n",
       "       [0.14368793],\n",
       "       [0.12972057],\n",
       "       [0.11914337],\n",
       "       [0.2846539 ],\n",
       "       [0.40668705],\n",
       "       [0.09048045],\n",
       "       [0.1123476 ],\n",
       "       [0.12958276],\n",
       "       [0.12164974],\n",
       "       [0.18382078],\n",
       "       [0.6245198 ],\n",
       "       [0.02563891],\n",
       "       [0.18920892],\n",
       "       [0.9833288 ],\n",
       "       [0.26742515],\n",
       "       [0.19491199],\n",
       "       [0.33894086],\n",
       "       [0.05695888],\n",
       "       [0.43358362],\n",
       "       [0.13696691],\n",
       "       [0.40318978],\n",
       "       [0.20334205],\n",
       "       [0.98210883],\n",
       "       [0.12126753],\n",
       "       [       nan],\n",
       "       [0.4179175 ],\n",
       "       [0.13000345],\n",
       "       [0.12936902],\n",
       "       [0.9812605 ],\n",
       "       [0.62411445],\n",
       "       [0.33894086],\n",
       "       [0.54429007],\n",
       "       [0.6116969 ],\n",
       "       [0.45677602],\n",
       "       [0.9241624 ],\n",
       "       [0.12111083],\n",
       "       [0.14545321],\n",
       "       [0.50005865],\n",
       "       [0.3318585 ],\n",
       "       [0.17989239],\n",
       "       [0.9791944 ],\n",
       "       [0.62952423],\n",
       "       [0.12120703],\n",
       "       [0.12149698],\n",
       "       [0.10102937],\n",
       "       [0.12115088],\n",
       "       [0.03506386],\n",
       "       [0.91234666],\n",
       "       [0.9380962 ],\n",
       "       [0.2995776 ],\n",
       "       [0.8117521 ],\n",
       "       [0.93584335],\n",
       "       [0.17086437],\n",
       "       [0.44002506],\n",
       "       [0.9863627 ],\n",
       "       [0.12124199],\n",
       "       [0.97502494],\n",
       "       [0.15114713],\n",
       "       [0.91645426],\n",
       "       [0.09943843],\n",
       "       [0.02546352],\n",
       "       [0.14723644],\n",
       "       [0.16274607],\n",
       "       [0.4025367 ],\n",
       "       [0.38774517],\n",
       "       [0.10101816],\n",
       "       [0.71394616],\n",
       "       [0.11857715],\n",
       "       [0.83978796],\n",
       "       [0.64782333],\n",
       "       [0.1935822 ],\n",
       "       [0.6124994 ],\n",
       "       [0.62800753],\n",
       "       [0.6478788 ],\n",
       "       [0.55038553],\n",
       "       [0.9106485 ],\n",
       "       [0.18226033],\n",
       "       [0.40223008],\n",
       "       [0.57627404],\n",
       "       [0.18620664],\n",
       "       [0.976897  ],\n",
       "       [0.12616754],\n",
       "       [0.12707463],\n",
       "       [0.12111953],\n",
       "       [0.30851012],\n",
       "       [0.8541393 ],\n",
       "       [0.09573603],\n",
       "       [0.3567447 ],\n",
       "       [0.6120058 ],\n",
       "       [0.4890368 ],\n",
       "       [0.9628407 ],\n",
       "       [0.12129456],\n",
       "       [0.91580176],\n",
       "       [0.1407162 ],\n",
       "       [0.92547375],\n",
       "       [0.14052466],\n",
       "       [0.9684099 ],\n",
       "       [0.5189708 ],\n",
       "       [0.1331191 ],\n",
       "       [0.61173224],\n",
       "       [0.11965713],\n",
       "       [0.15494597],\n",
       "       [0.3340469 ],\n",
       "       [0.9818984 ],\n",
       "       [0.10526887],\n",
       "       [0.12126455],\n",
       "       [0.40879923],\n",
       "       [0.14472237],\n",
       "       [0.28959653],\n",
       "       [0.14429453],\n",
       "       [0.89399636],\n",
       "       [0.9836116 ],\n",
       "       [0.9675473 ],\n",
       "       [0.7671063 ],\n",
       "       [0.4779373 ],\n",
       "       [0.12126604],\n",
       "       [0.12346774],\n",
       "       [0.37511536],\n",
       "       [0.9300925 ],\n",
       "       [0.1282784 ],\n",
       "       [0.9230703 ],\n",
       "       [0.56896996],\n",
       "       [0.9541524 ],\n",
       "       [0.14477056],\n",
       "       [0.5183896 ],\n",
       "       [0.13062054],\n",
       "       [0.11912644],\n",
       "       [0.12120703],\n",
       "       [0.12124199],\n",
       "       [0.12129456],\n",
       "       [0.92853475],\n",
       "       [0.14050901],\n",
       "       [0.08518779],\n",
       "       [0.14056864],\n",
       "       [0.867825  ],\n",
       "       [0.7813852 ],\n",
       "       [0.17055225],\n",
       "       [0.12126753],\n",
       "       [0.34462345],\n",
       "       [0.12120703],\n",
       "       [0.61236715],\n",
       "       [0.16689876],\n",
       "       [0.3630007 ],\n",
       "       [0.12124199],\n",
       "       [0.9886005 ],\n",
       "       [0.56905586],\n",
       "       [0.12115014],\n",
       "       [0.92576236],\n",
       "       [0.17403597],\n",
       "       [0.14015478],\n",
       "       [0.1681194 ],\n",
       "       [0.20196351],\n",
       "       [0.6257992 ],\n",
       "       [0.54136324],\n",
       "       [0.61173224],\n",
       "       [0.7204218 ],\n",
       "       [0.77429855],\n",
       "       [0.1168896 ],\n",
       "       [0.12115452],\n",
       "       [0.5271663 ],\n",
       "       [0.12115088],\n",
       "       [0.12129456],\n",
       "       [0.4187822 ],\n",
       "       [0.6051253 ],\n",
       "       [0.12115088],\n",
       "       [0.29532212],\n",
       "       [0.1177834 ],\n",
       "       [0.12298539],\n",
       "       [0.95490503],\n",
       "       [0.07570651],\n",
       "       [0.41743195],\n",
       "       [0.12071943],\n",
       "       [0.11909598],\n",
       "       [0.17959258],\n",
       "       [0.14441466],\n",
       "       [0.1301522 ],\n",
       "       [0.61173224],\n",
       "       [0.9593042 ],\n",
       "       [0.45663002],\n",
       "       [0.625571  ],\n",
       "       [0.29714853],\n",
       "       [0.4012288 ],\n",
       "       [0.15830448],\n",
       "       [0.13636008],\n",
       "       [0.12121135],\n",
       "       [0.56009924],\n",
       "       [0.972649  ],\n",
       "       [0.6526363 ],\n",
       "       [0.4711445 ],\n",
       "       [0.23144591],\n",
       "       [0.12187654],\n",
       "       [0.17345414],\n",
       "       [0.12291425],\n",
       "       [0.12576687],\n",
       "       [0.18382078],\n",
       "       [0.3807682 ],\n",
       "       [0.97743964],\n",
       "       [0.13258347],\n",
       "       [0.88542604],\n",
       "       [0.3642366 ],\n",
       "       [0.17699355],\n",
       "       [0.21455002],\n",
       "       [0.7453008 ],\n",
       "       [0.35634547],\n",
       "       [0.12115014],\n",
       "       [0.58830804],\n",
       "       [0.12190166],\n",
       "       [0.39422667],\n",
       "       [0.16482809],\n",
       "       [0.1073885 ],\n",
       "       [0.215574  ],\n",
       "       [0.12115088],\n",
       "       [0.24203855],\n",
       "       [0.11906222],\n",
       "       [0.01997253],\n",
       "       [0.92859775],\n",
       "       [0.1662952 ],\n",
       "       [0.65723956],\n",
       "       [0.18382078],\n",
       "       [0.5516781 ],\n",
       "       [0.18932572],\n",
       "       [0.92374754],\n",
       "       [0.9711256 ],\n",
       "       [0.18226033],\n",
       "       [0.30541143],\n",
       "       [0.1035521 ],\n",
       "       [0.8107114 ],\n",
       "       [0.29540652],\n",
       "       [0.9768756 ],\n",
       "       [0.12126455],\n",
       "       [0.12124199],\n",
       "       [0.55037147],\n",
       "       [0.01748312],\n",
       "       [0.90420663],\n",
       "       [0.92374754],\n",
       "       [0.12236565],\n",
       "       [0.9855193 ],\n",
       "       [0.13036427],\n",
       "       [0.0909363 ],\n",
       "       [0.68765026],\n",
       "       [0.97155905],\n",
       "       [0.17498598],\n",
       "       [0.18843222],\n",
       "       [0.984915  ],\n",
       "       [0.24273306],\n",
       "       [0.14046559],\n",
       "       [0.96737087],\n",
       "       [0.9708562 ],\n",
       "       [0.47646692],\n",
       "       [0.21256387],\n",
       "       [0.29000574],\n",
       "       [0.21921477],\n",
       "       [0.12124199],\n",
       "       [0.12297562],\n",
       "       [0.62592286],\n",
       "       [0.6070034 ],\n",
       "       [0.17692196],\n",
       "       [0.8400228 ],\n",
       "       [0.12952715],\n",
       "       [0.10994753],\n",
       "       [0.14049017],\n",
       "       [0.2567848 ],\n",
       "       [0.45480695],\n",
       "       [0.9697044 ],\n",
       "       [0.40641615],\n",
       "       [0.13164896],\n",
       "       [0.0957045 ],\n",
       "       [0.98704636],\n",
       "       [0.12915853],\n",
       "       [0.97231853],\n",
       "       [0.13676438],\n",
       "       [0.11962324],\n",
       "       [0.9838686 ],\n",
       "       [0.14312744],\n",
       "       [0.98032326],\n",
       "       [0.49722835],\n",
       "       [0.3085057 ],\n",
       "       [0.22578183],\n",
       "       [0.17986053],\n",
       "       [0.5314792 ],\n",
       "       [0.6116705 ],\n",
       "       [0.7670673 ],\n",
       "       [0.61173224],\n",
       "       [0.98694605],\n",
       "       [0.6117852 ],\n",
       "       [0.12129456],\n",
       "       [0.9832262 ],\n",
       "       [0.11569008],\n",
       "       [0.12129451],\n",
       "       [0.17303954]], dtype=float32)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
